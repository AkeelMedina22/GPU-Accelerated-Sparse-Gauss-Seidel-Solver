{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q-DjuTLADoI"
      },
      "source": [
        "# GPU-Accelerated Gauss-Seidel Sparse Iterative Solver using Graph Coloring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYngqUpJA-Kd"
      },
      "source": [
        "### Load Suite Sparse matrix for testing\n",
        "Use ssget and search for 'filter2D', a symmetric matrix used in structural problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBI_FHqhBBii",
        "outputId": "6ae6ffb6-68be-4348-f409-9f5b11af766a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install ssgetpy --quiet\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git --quiet\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "TW7YDDReBW3u",
        "outputId": "cea93306-ea1b-4134-883f-44e6d562e174"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table><thead><th>Id</th><th>Group</th><th>Name</th><th>Rows</th><th>Cols</th><th>NNZ</th><th>DType</th><th>2D/3D Discretization?</th><th>SPD?</th><th>Pattern Symmetry</th><th>Numerical Symmetry</th><th>Kind</th><th>Spy Plot</th></thead><tbody><tr><td>1430</td><td><a href=\"https://sparse.tamu.edu/Oberwolfach\" target=\"_blank\">Oberwolfach</a></td><td><a href=\"https://sparse.tamu.edu/Oberwolfach/filter2D\" target=\"_blank\">filter2D</a></td><td>1668</td><td>1668</td><td>10750</td><td>real</td><td>Yes</td><td>No</td><td>1.0</td><td>1.0</td><td>model reduction problem</td><td><img src=\"https://sparse.tamu.edu/files/Oberwolfach/filter2D.png\"></td></tr></tbody></table>"
            ],
            "text/plain": [
              "[Matrix(1430, 'Oberwolfach', 'filter2D', 1668, 1668, 10750, 'real', True, False, 1.0, 1.0, 'model reduction problem', 'https://sparse.tamu.edu/files/Oberwolfach/filter2D.png')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ssgetpy\n",
        "ssgetpy.search(name=\"filter2D\") # Ideal matrix after searching properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2dac522d2199417aa5c51641cbf88ec4",
            "6841fdb9a80f4059a28288519d418b5a",
            "1fae8cdb3a3b4821b1ee85304ac63d06",
            "64423b41e0c0452b90af24be3b3704d7",
            "c9b438f4bc7941e98e6209ce49894dbf",
            "28bfe307f325422586e8c45a0c6d1654",
            "7ba385fee67f4c389a016731b50637ad",
            "2be3e82fd2e54d559a951acaea32e2d7",
            "135b483c382348b8a87804e29f6d063b",
            "14c4620a666d404ba571bad32c3bf069",
            "c579f815ddd94c76ac2c518a8b2bf3cb"
          ]
        },
        "id": "BxwieX9mBGR3",
        "outputId": "a836ddd9-b884-499c-9717-124f1685f615"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dac522d2199417aa5c51641cbf88ec4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "flowmeter0:   0%|          | 0/487663 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('content/flowmeter0', 'content/flowmeter0.tar.gz')"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ssgetpy\n",
        "result = ssgetpy.search(name=\"flowmeter0\")[0]\n",
        "result.download(format='MM', destpath='content/', extract=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fucuNTsoANjF"
      },
      "source": [
        "### CPU Gauss-Seidel\n",
        "\n",
        "This approach is given in a gist by Eric Arneback at https://gist.github.com/Erkaman/b34b3531e209a1db38e259ea53ff0be9. The graph coloring is not used in this purely sequential approach, and the following cell considers each element of the *x* vector to updated one by one from start to end.\n",
        "\n",
        "This sequential version of Gauss-Seidel serves as a base case, and it is used for testing the convergence of Sequential Gauss Seidel on the Suite Sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrnzTrtL_9dv",
        "outputId": "194f7686-1518-470e-ecab-ab1fb3847a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting cpu.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile cpu.cpp\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "#include <set>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <algorithm>\n",
        "\n",
        "const float EPS = 0.00001f;\n",
        "typedef std::vector<int> Partition;\n",
        "\n",
        "// vector of dimension Nx1\n",
        "class Vec {\n",
        "public:\n",
        "  int N;\n",
        "\tfloat* v;\n",
        "\n",
        "\tVec(int n) {\n",
        "    N = n;\n",
        "    v = new float[N];\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tv[i] = 0.0f;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t~Vec()\n",
        "\t{\n",
        "\t\tdelete[] v;\n",
        "\t}\n",
        "\n",
        "\tvoid print() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", v[i]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "};\n",
        "\n",
        "// matrix of dimension NxN.\n",
        "class Mat {\n",
        "public:\n",
        "  int N;\n",
        "\tfloat* m;\n",
        "\n",
        "\tMat(int n) {\n",
        "    N = n;\n",
        "    m = new float[N*N];\n",
        "\t\tfor (int i = 0; i < N*N; ++i) {\n",
        "\t\t\tm[i] = 0.0f;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t~Mat()\n",
        "\t{\n",
        "\t\tdelete[] m;\n",
        "\t}\n",
        "\n",
        "\tvoid print() {\n",
        "\t\tfor (int i = 0; i < N*N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", m[i]);\n",
        "\t\t\tif (i % N == 0){printf(\"\\n\");}\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "\tVec* mult(const Vec* v) const {\n",
        "\t\tVec* r = new Vec(N);\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tr->v[row] += this->m[row*N+col] * v->v[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\treturn r;\n",
        "\t}\n",
        "};\n",
        "\n",
        "\n",
        "int gauss_seidel(Vec* x, const Vec* b, const Mat* m, float tol, int maxiter, int N) {\n",
        "\n",
        "\tint iter;\n",
        "\tfloat old_norm = 0.0f;\n",
        "\tfor (iter = 0; iter < maxiter; ++iter) {\n",
        "\t\tfor (int i = 0; i < N; i++) {\n",
        "\t\t\t\tfloat s = 0.0f;\n",
        "\t\t\t\tfloat c = 0.0f;\n",
        "\t\t\t\tfor (int j = 0; j < N; ++j) {\n",
        "\t\t\t\t\tif (j != i) {\n",
        "\t\t\t\t\t\t//s += m->m[i*N+j] * x->v[j];\n",
        "\t\t\t\t\t\tfloat y = (m->m[i*N+j] * x->v[j]) - c;\n",
        "\t\t\t\t\t\tfloat t = s + y;\n",
        "\t\t\t\t\t\tc = (t - s) - y;\n",
        "\t\t\t\t\t\ts = t;\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t\t\tx->v[i] = (1.0f / m->m[i*N+i]) * (b->v[i] - s);\n",
        "\t\t}\n",
        "\n",
        "\t\tVec* mx = new Vec(N);\n",
        "\t\tmx = m->mult(x);\n",
        "\n",
        "\t\tfloat norm = 0.0f;\n",
        "\t\tfloat c = 0.0f;\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tfloat a = mx->v[i] - b->v[i];\n",
        "\t\t\t//norm += a*a;\n",
        "\t\t\tfloat y = a*a - c;\n",
        "\t\t\tfloat t = norm + y;\n",
        "\t\t\tc = (t-norm) - y;\n",
        "\t\t\tnorm = t;\n",
        "\t\t}\n",
        "\t\tnorm = sqrt(norm);\n",
        "\t\tif (fabs(norm-old_norm) < tol) {\n",
        "\t\t\tbreak;\n",
        "\t\t}\n",
        "\t\told_norm = norm;\n",
        "\t\tdelete mx;\n",
        "\t}\n",
        "\n",
        "\treturn iter;\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tsrand(13000);\n",
        "\n",
        "  std::ifstream file(\"content/flowmeter0/flowmeter0.mtx\");\n",
        "  int num_row, num_col, num_lines, N;\n",
        "\n",
        "  while (file.peek() == '%') file.ignore(2048, '\\n');\n",
        "\n",
        "  file >> num_row>> num_col >> num_lines;\n",
        "\n",
        "  N = num_row;\n",
        "\n",
        "\tMat* m = new Mat(N);\n",
        "  std::fill(m->m, m->m + num_row * num_col, 0.0f);\n",
        "  for (int l = 0; l < num_lines; l++)\n",
        "  {\n",
        "      float data;\n",
        "      int row, col;\n",
        "      file >> row >> col >> data;\n",
        "      m->m[(row -1) + (col -1) * num_row] = data;\n",
        "  }\n",
        "\n",
        "  file.close();\n",
        "\n",
        "\tint nonZeros = 0;\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tfor (int j = i; j < N; ++j) {\n",
        "\t\t\tif (fabs(m->m[i*N+j]) > EPS) {\n",
        "\t\t\t\tnonZeros++;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"Normal Gauss Seidel \\npercent of non-zeros of M: %d%%\\n\", int(100.0f * float(nonZeros) / float(N*N)));\n",
        "\n",
        "\tVec* expected_solution = new Vec(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\texpected_solution->v[i] = 8.0f * float(rand() % 100) / 100.0f - 4.0f;\n",
        "\t}\n",
        "\n",
        "\tVec* b = new Vec(N);\n",
        "\tb = m->mult(expected_solution);\n",
        "\n",
        "\t/*\n",
        "\tWith that, we have generated a linear system\n",
        "\tM*x = b.\n",
        "\tNow let's solve it!\n",
        "\t*/\n",
        "\n",
        "\tVec* x = new Vec(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tx->v[i] = 0.0f;\n",
        "\t}\n",
        "\n",
        "\tprintf(\"solving linear system where N = %d\", N);\n",
        "\n",
        "\tprintf(\"\\n\");\n",
        "\n",
        "\tauto started = std::chrono::high_resolution_clock::now();\n",
        "\tint iter = gauss_seidel(x, b, m, 0.001f, 10000, N);\n",
        "\tauto done = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\tstd::cout << \"Gauss Seidel CPU time: \" << std::chrono::duration_cast<std::chrono::milliseconds>(done - started).count() << \"ms\\n\";\n",
        "\tprintf(\"number of iterations: %d\\n\", iter);\n",
        "\n",
        "\tdelete m;\n",
        "\tdelete x;\n",
        "\tdelete b;\n",
        "\tdelete expected_solution;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4geCNMj8Dq96",
        "outputId": "87a84a43-7c8f-4a8f-920a-4af603f2fcd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal Gauss Seidel \n",
            "percent of non-zeros of M: 0%\n",
            "solving linear system where N = 9669\n",
            "Gauss Seidel CPU time: 30396ms\n",
            "number of iterations: 20\n"
          ]
        }
      ],
      "source": [
        "!g++ cpu.cpp -o cpu\n",
        "!./cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_KcxG0oGHdY"
      },
      "source": [
        "### Comparing Brooks Vizing coloring with CSRColor\n",
        "\n",
        "Using the CPU graph coloring algorthm (Brooks Vizing) that was also used by Vivace and provided by Eric Arneback, we observe the performance of the code, as well as the quality of the result, based on the number of colors received. Having fewer colors is ideal because there will be fewer kernel calls per iteration and a significant speedup in the Gauss-Seidel Kernel. However, the time taken by the graph coloring should also be small enough for real-time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITUYD0WWGMw8",
        "outputId": "b1e08d1f-010f-472c-83e1-538939c9344c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing cpucoloringgpugs.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cpucoloringgpugs.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "#include <set>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <algorithm>\n",
        "\n",
        "const float SHRINKING_FACTOR = 7.5f;\n",
        "const int NO_PROGRESS_STREAK_THRESHOLD = 100;\n",
        "const float EPS = 0.00001f;\n",
        "typedef std::vector<int> Partition;\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "\tif (err != cudaSuccess) {\n",
        "\t\tfprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "\t}\n",
        "\treturn err;\n",
        "}\n",
        "\n",
        "// vector of dimension Nx1\n",
        "template <class T>\n",
        "class gpuVec {\n",
        "public:\n",
        "\tT* v;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuVec(int size) {\n",
        "    N = size;\n",
        "\t\tcudaMallocManaged(&v, (T)(size * (int)sizeof(int)));\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tv[i] = 0;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuVec()\n",
        "\t{\n",
        "\t\tcudaFree(v);\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", v[i]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "};\n",
        "\n",
        "// matrix of dimension NxN.\n",
        "class gpuMat {\n",
        "public:\n",
        "\tfloat* m;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuMat(int n) {\n",
        "    N = n;\n",
        "\t\tcudaMallocManaged(&m, (float)(N * N * (int)sizeof(float)));\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tm[i] = 0.0f;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuMat()\n",
        "\t{\n",
        "\t\tcudaFree(m);\n",
        "\t}\n",
        "\n",
        "\t__host__ void printdiag() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\t{ printf(\"%f, \", m[i * N + i]); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", m[i]);\n",
        "\t\t\tif (i % N == 0 && i != 0) { printf(\"\\n\"); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "  // only used to get solution, b, from initial matrix, m.\n",
        "  __host__ gpuVec<float>* gpu_mult(const gpuVec<float>* v, gpuVec<float>* r) const {\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tr->v[row] += this->m[row * N + col] * v->v[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\treturn r;\n",
        "\t}\n",
        "};\n",
        "\n",
        "std::vector<int> randomized_graph_coloring(gpuMat* m, int* colors, int N) {\n",
        "\tstd::set<int> neighbours[N];\n",
        "\n",
        "\tint node_colors[N]; // colors assigned to the nodes.\n",
        "\tint next_color[N]; // next color of every node, in case the palette runs out.\n",
        "\tstd::set<int> node_palettes[N]; // palettes of the nodes.\n",
        "\tstd::set<int> U;\n",
        "\n",
        "\t/*\n",
        "\tEvery node needs to know about it's neighbours. so find that.\n",
        "\tThere is an edge between two nodes i and j, if the matrix coefficient at row i, column j is non-zero.\n",
        "\t*/\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tfor (int j = 0; j < N; ++j) {\n",
        "\t\t\tif (i != j && fabs(m->m[i * N + j]) > EPS) {\n",
        "\n",
        "\t\t\t\t// if necessary, make j a neighbour of i.\n",
        "\t\t\t\tif (neighbours[i].find(j) == neighbours[i].end()) {\n",
        "\t\t\t\t\tneighbours[i].insert(j);\n",
        "\t\t\t\t}\n",
        "\n",
        "\t\t\t\t// if necessary, make i a neighbour of j.\n",
        "\t\t\t\tif (neighbours[j].find(i) == neighbours[j].end()) {\n",
        "\t\t\t\t\tneighbours[j].insert(i);\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t// calculate max degree of a single node.\n",
        "\tint delta_v = 0;\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tif ((int)neighbours[i].size() > delta_v) {\n",
        "\t\t\tdelta_v = neighbours[i].size();\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t// initially, every node has a palette of size delta_v/shrinking_factor.\n",
        "\t// the maximum number of colors necessary for a graph coloring is delta_v, but many\n",
        "\t// graphs won't need that many colors. therefore, we choose to shrink delta_v by a shrinking factor.\n",
        "\t// if the shrinking factor is too big, so that the problem is unsolvable, then more colors will be added on the fly.\n",
        "\tint max_color = int((float)delta_v / SHRINKING_FACTOR);\n",
        "\tif (max_color <= 0) {\n",
        "\t\tmax_color = 1;\n",
        "\t}\n",
        "\t//max_color = 2;\n",
        "\n",
        "\t// initialize the palettes for all the node.\n",
        "\t// the colors in the palette will be chosen randomly from, for all the remaining nodes in U.\n",
        "\tfor (int iv = 0; iv < N; ++iv) {\n",
        "\t\tfor (int ic = 0; ic < max_color; ++ic) {\n",
        "\t\t\tnode_palettes[iv].insert(ic);\n",
        "\t\t}\n",
        "\t\tnext_color[iv] = max_color;\n",
        "\t}\n",
        "\n",
        "\tfor (int iv = 0; iv < N; ++iv) {\n",
        "\t\tU.insert(iv);\n",
        "\t}\n",
        "\n",
        "\t// keep track of the number of iterations with no progress.\n",
        "\tint no_progress_streak = 0;\n",
        "\n",
        "\t/*\n",
        "\tIf a node has found a color that solves the graph coloring for that node, then remove from U.\n",
        "\tOnce U is empty, the graph coloring problem is done.\n",
        "\t*/\n",
        "\twhile (U.size()) {\n",
        "\n",
        "\t\t// all remaining nodes in U are given a random color.\n",
        "\t\tfor (int iv : U) {\n",
        "\t\t\t// get random color from palette, and assign it.\n",
        "\t\t\tint m = rand() % node_palettes[iv].size();\n",
        "\t\t\tauto setIt = node_palettes[iv].begin();\n",
        "\t\t\tadvance(setIt, m);\n",
        "\n",
        "\t\t\tnode_colors[iv] = *setIt;\n",
        "\t\t}\n",
        "\n",
        "\t\tstd::set<int> temp;\n",
        "\n",
        "\n",
        "\t\t/*\n",
        "\t\t  Now let's find all the nodes whose colors are different from all their neighbours.\n",
        "\t\t  Those nodes will be removed from U, because they are done, with respect to the graph coloring problem.\n",
        "\t\t*/\n",
        "\t\tfor (int iv : U) {\n",
        "\n",
        "\t\t\tint icolor = node_colors[iv];\n",
        "\n",
        "\t\t\t/*\n",
        "\t\t\tCheck if graph coloring property is solved for node.\n",
        "\t\t\t*/\n",
        "\t\t\tbool different_from_neighbours = true;\n",
        "\t\t\tfor (int neighbour : neighbours[iv]) {\n",
        "\n",
        "\t\t\t\tif (node_colors[neighbour] == icolor) {\n",
        "\t\t\t\t\tdifferent_from_neighbours = false;\n",
        "\t\t\t\t\tbreak;\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\tif (different_from_neighbours) {\n",
        "\t\t\t\t// found the right color for this one.\n",
        "\t\t\t\t// so remove from U.\n",
        "\n",
        "\t\t\t\t// also, the neighbours of iv can't use this color anymore.\n",
        "\t\t\t\t// so remove it from their palettes.\n",
        "\t\t\t\tfor (int neighbour : neighbours[iv]) {\n",
        "\t\t\t\t\tnode_palettes[neighbour].erase(icolor);\n",
        "\t\t\t\t}\n",
        "\n",
        "\t\t\t}\n",
        "\t\t\telse {\n",
        "\t\t\t\t// not a correct color. don't remove from U.\n",
        "\t\t\t\ttemp.insert(iv);\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\t// feed the hungry!\n",
        "\t\t\t// if palette empty, we add more colors on the fly.\n",
        "\t\t\t// if we don't do this, the algorithm will get stuck in a loop.\n",
        "\t\t\tif (node_palettes[iv].empty()) {\n",
        "\t\t\t\tnode_palettes[iv].insert(next_color[iv]++);\n",
        "\t\t\t}\n",
        "\n",
        "\t\t}\n",
        "\n",
        "\t\tif (U.size() == temp.size()) {\n",
        "\t\t\tno_progress_streak++;\n",
        "\n",
        "\t\t\t// if no progress for too many iterations, we have no choice but to feed a random node.\n",
        "\t\t\tif (no_progress_streak > NO_PROGRESS_STREAK_THRESHOLD) {\n",
        "\t\t\t\tint m = rand() % U.size();\n",
        "\t\t\t\tauto setIt = U.begin();\n",
        "\t\t\t\tadvance(setIt, m);\n",
        "\n",
        "\t\t\t\tnode_palettes[*setIt].insert(next_color[*setIt]++);\n",
        "\n",
        "\t\t\t\tno_progress_streak = 0;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\n",
        "\t\tU = temp;\n",
        "\t}\n",
        "\n",
        "\t// find the number of colors used in our solution.\n",
        "\t// this is also the number of partitions.\n",
        "\tint num_colors = 0;\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tif (next_color[i] > num_colors) {\n",
        "\t\t\tnum_colors = next_color[i];\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t/*\n",
        "\tFinally, we collect all the partitions then.\n",
        "\t*/\n",
        "\tstd::vector<Partition> partitions;\n",
        "\tfor (int ic = 0; ic < num_colors; ++ic) {\n",
        "\t\tPartition partition;\n",
        "\n",
        "\t\t/*\n",
        "\t\tThe first partition is all nodes that use color 0,\n",
        "\t\tthe second partition use color 1, and so on.\n",
        "\t\t*/\n",
        "\t\tfor (int inode = 0; inode < N; ++inode) {\n",
        "\t\t\tif (node_colors[inode] == ic) {\n",
        "\t\t\t\tpartition.push_back(inode);\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\n",
        "\t\tpartitions.push_back(partition);\n",
        "\t}\n",
        "\n",
        "\tstd::vector<int> indices;\n",
        "\tindices.push_back(0);\n",
        "\tint row = 0;\n",
        "\tfor (Partition partition : partitions) {\n",
        "\t\tfor (int variable : partition) {\n",
        "\t\t\tcolors[row] = variable;\n",
        "\t\t\trow++;\n",
        "\t\t}\n",
        "\t\tindices.push_back(row);\n",
        "\t}\n",
        "\n",
        "\treturn indices;\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tsrand(13000);\n",
        "\n",
        "\tstd::ifstream file(\"content/t2dal_a/t2dal_a.mtx\");\n",
        "  int num_row, num_col, num_lines, N;\n",
        "\n",
        "  while (file.peek() == '%') file.ignore(2048, '\\n');\n",
        "\n",
        "  file >> num_row>> num_col >> num_lines;\n",
        "\n",
        "  N = num_row;\n",
        "\n",
        "\tgpuMat* m = new gpuMat(N);\n",
        "  std::fill(m->m, m->m + num_row * num_col, 0.0f);\n",
        "  for (int l = 0; l < num_lines; l++)\n",
        "  {\n",
        "      float data;\n",
        "      int row, col;\n",
        "      file >> row >> col >> data;\n",
        "      m->m[(row -1) + (col -1) * num_row] = data;\n",
        "  }\n",
        "\n",
        "  file.close();\n",
        "\n",
        "\n",
        "\tint nonZeros = 0;\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tfor (int j = i; j < N; ++j) {\n",
        "\t\t\tif (fabs(m->m[i * N + j]) > EPS) {\n",
        "\t\t\t\tnonZeros++;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"GPU Gauss Seidel with Graph Coloring \\npercent of non-zeros of M: %d%%\\n\", int(100.0f * float(nonZeros) / float(N * N)));\n",
        "\n",
        "\tgpuVec<float>* expected_solution = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\texpected_solution->v[i] = 8.0f * float(rand() % 100) / 100.0f - 4.0f;\n",
        "\t}\n",
        "\n",
        "\tgpuVec<float>* b = new gpuVec<float>(N);\n",
        "\tb = m->gpu_mult(expected_solution, b);\n",
        "\n",
        "\t/*\n",
        "\tWith that, we have generated a linear system\n",
        "\tM*x = b.\n",
        "\tNow let's solve it!\n",
        "\t*/\n",
        "\n",
        "\tgpuVec<float>* x = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tx->v[i] = 0.0f;\n",
        "\t}\n",
        "\n",
        "\tprintf(\"solving linear system where N = %d\", N);\n",
        "\tprintf(\"\\n\");\n",
        "\n",
        "\t// graph coloring to partition the problem.\n",
        "\tgpuVec<int>* colors = new gpuVec<int>(N);\n",
        "\tauto started = std::chrono::high_resolution_clock::now();\n",
        "\tstd::vector<int> h_indices = randomized_graph_coloring(m, colors->v, N);\n",
        "\tauto done = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\tstd::cout << \"Graph Coloring CPU time: \" << std::chrono::duration_cast<std::chrono::milliseconds>(done - started).count() << \"ms\\n\";\n",
        "\tprintf(\"number of partitions: %zd\\n\", h_indices.size());\n",
        "\n",
        "  delete m;\n",
        "\tdelete x;\n",
        "\tdelete b;\n",
        "\tdelete expected_solution;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnkpUSSwN-fY",
        "outputId": "449e351b-a918-4741-c655-3615dd47be67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Gauss Seidel with Graph Coloring \n",
            "percent of non-zeros of M: 0%\n",
            "solving linear system where N = 4257\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!nvcc cpucoloringgpugs.cu -o gpu1\n",
        "!./gpu1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PwXEXRT51g6",
        "outputId": "995cd02a-94ff-4d0d-ef0f-79ac6160b08f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting csrcolortest.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile csrcolortest.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "#include <set>\n",
        "#include <vector>\n",
        "#include <cusparse.h>\n",
        "#include <cusparse_v2.h>\n",
        "#include <algorithm>\n",
        "#include <fstream>\n",
        "\n",
        "const float EPS = 0.00001f;\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "\tif (err != cudaSuccess) {\n",
        "\t\tfprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "\t}\n",
        "\treturn err;\n",
        "}\n",
        "\n",
        "// vector of dimension Nx1\n",
        "template <class T>\n",
        "class gpuVec {\n",
        "public:\n",
        "\tT* v;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuVec(int size) {\n",
        "    N = size;\n",
        "\t\tcudaMallocManaged(&v, (T)(size * (int)sizeof(int)));\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tv[i] = 0;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuVec()\n",
        "\t{\n",
        "\t\tcudaFree(v);\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", v[i]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "};\n",
        "\n",
        "// matrix of dimension NxN.\n",
        "class gpuMat {\n",
        "public:\n",
        "\tfloat* m;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuMat(int n) {\n",
        "    N = n;\n",
        "\t\tcudaMallocManaged(&m, (float)(N * N * (int)sizeof(float)));\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tm[i] = 0.0f;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuMat()\n",
        "\t{\n",
        "\t\tcudaFree(m);\n",
        "\t}\n",
        "\n",
        "\t__host__ void printdiag() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\t{ printf(\"%f, \", m[i * N + i]); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", m[i]);\n",
        "\t\t\tif (i % N == 0 && i != 0) { printf(\"\\n\"); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "  // only used to get solution, b, from initial matrix, m.\n",
        "  __host__ gpuVec<float>* gpu_mult(const gpuVec<float>* v, gpuVec<float>* r) const {\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tr->v[row] += this->m[row * N + col] * v->v[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\treturn r;\n",
        "\t}\n",
        "};\n",
        "\n",
        "std::vector<int> color(int N, gpuMat* m, gpuVec<float>* x, gpuVec<float>* b, int* indices, int* max, int* dANnzPerRow,\n",
        "\tfloat* dCsrValA, int* dCsrRowPtrA, int* dCsrColIndA, int* totalANnz, cusparseHandle_t handle,\n",
        "\tcusparseMatDescr_t Adescr, float* dM, float* fractiontoColor, int* nrows, int* ncolors, int* coloring, int* reordering, cusparseColorInfo_t info)\n",
        "{\n",
        "\n",
        "  float* hCsrVal = (float*)malloc(*totalANnz * sizeof(float));\n",
        "\tint* hCsrRowPtr = (int*)malloc((N+1) * sizeof(int));\n",
        "  int* hCsrColPtr = (int*)malloc(*totalANnz * sizeof(int));\n",
        "\n",
        "\n",
        "\tcusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
        "\t\tdCsrValA, dCsrRowPtrA, dCsrColIndA);\n",
        "\n",
        "\tcusparseScsrcolor(handle, *nrows, *totalANnz, Adescr, dCsrValA, dCsrRowPtrA, dCsrColIndA, fractiontoColor, ncolors, coloring, reordering, info);\n",
        "\n",
        "\tprintf(\"colors used: %d\\nfraction to color: %f\\n\", *ncolors, *fractiontoColor);\n",
        "\n",
        "\n",
        "  cudaMemcpy(hCsrVal, dCsrValA, *totalANnz * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hCsrRowPtr, dCsrRowPtrA, (N+1) * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hCsrColPtr, dCsrColIndA, *totalANnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "  int old = 0;\n",
        "\t*max = 0;\n",
        "  for (int i = 0; i < (N+1); i++)\n",
        "  {\n",
        "\t\tif (hCsrRowPtr[i] - old > *max)\n",
        "\t\t{\n",
        "\t\t\t*max = hCsrRowPtr[i] - old;\n",
        "\t\t}\n",
        "  \told = hCsrRowPtr[i];\n",
        "  }\n",
        "\n",
        "\n",
        "\tint* h_colors = (int*)malloc(N * sizeof(int));\n",
        "\tint* h_colindices = (int*)malloc(N * sizeof(int));\n",
        "\tcudaMemcpy(h_colors, coloring, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\tcudaMemcpy(h_colindices, reordering, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\tstd::vector<std::pair<int, int>> new_order;\n",
        "\tfor (int i = 0; i < N; i++)\n",
        "\t{\n",
        "\t\tnew_order.push_back(std::make_pair(h_colors[i], h_colindices[i]));\n",
        "\t}\n",
        "\tstd::sort(std::begin(new_order), std::end(new_order));\n",
        "\n",
        "\n",
        "\tstd::vector<int> colors;\n",
        "\tint prev_color = -1;\n",
        "\tgpuMat* new_m = new gpuMat(N);\n",
        "\tgpuVec<float>* new_x = new gpuVec<float>(N); // reorder expected solution, not the x vector\n",
        "\tgpuVec<float>* new_b = new gpuVec<float>(N);\n",
        "\n",
        "\tfor (int i = 0; i < N; i++)\n",
        "\t{\n",
        "\t\tif (prev_color != new_order[i].first)\n",
        "\t\t{\n",
        "\t\t\tcolors.push_back(i);\n",
        "\t\t\tprev_color = new_order[i].first;\n",
        "\t\t}\n",
        "\t\tindices[i] = new_order[i].second;\n",
        "\n",
        "\t\tfloat* m_pt = m->m + (new_order[i].second * N);\n",
        "\t\tfloat* x_pt = x->v + (new_order[i].second);\n",
        "\t\tfloat* b_pt = b->v + (new_order[i].second);\n",
        "\n",
        "\t\tfloat* m_new_pt = new_m->m + (i * N);\n",
        "\t\tfloat* x_new_pt = new_x->v + (i);\n",
        "\t\tfloat* b_new_pt = new_b->v + (i);\n",
        "\n",
        "\t\tmemcpy(m_new_pt, m_pt, N * (sizeof(float)));\n",
        "\t\tmemcpy(x_new_pt, x_pt, (sizeof(float)));\n",
        "\t\tmemcpy(b_new_pt, b_pt, (sizeof(float)));\n",
        "\t}\n",
        "\n",
        "\tm->m = new_m->m;\n",
        "\tx->v = new_x->v;\n",
        "\tb->v = new_b->v;\n",
        "\n",
        "\treturn colors;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\tsrand(0);\n",
        "\n",
        "  std::ifstream file(\"content/flowmeter0/flowmeter0.mtx\");\n",
        "  int num_row, num_col, num_lines, N;\n",
        "\n",
        "  while (file.peek() == '%') file.ignore(2048, '\\n');\n",
        "\n",
        "  file >> num_row>> num_col >> num_lines;\n",
        "\n",
        "  N = num_row;\n",
        "\n",
        "  gpuMat* m = new gpuMat(num_row);\n",
        "  std::fill(m->m, m->m + num_row * num_col, 0.0f);\n",
        "\n",
        "  for (int l = 0; l < num_lines; l++)\n",
        "  {\n",
        "      float data;\n",
        "      int row, col;\n",
        "      file >> row >> col >> data;\n",
        "      m->m[(row -1) + (col -1) * num_row] = data;\n",
        "  }\n",
        "\n",
        "  file.close();\n",
        "\n",
        "\tint nonZeros = 0;\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tfor (int j = i; j < N; ++j) {\n",
        "\t\t\tif (fabs(m->m[i * N + j]) > EPS) {\n",
        "\t\t\t\tnonZeros++;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"Gauss Seidel with Graph Coloring on the GPU using CuSparse\\npercent of non-zeros of M: %d%%\\n\", int(100.0f * float(nonZeros) / float(N * N)));\n",
        "\n",
        "\tgpuVec<float>* expected_solution = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\texpected_solution->v[i] = 8.0f * float(rand() % 100) / 100.0f - 4.0f;\n",
        "\t}\n",
        "\n",
        "\tgpuVec<float>* b = new gpuVec<float>(N);\n",
        "\tb = m->gpu_mult(expected_solution, b);\n",
        "\n",
        "\tgpuVec<float>* x = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tx->v[i] = 0.0f;\n",
        "\t}\n",
        "\n",
        "\tprintf(\"solving linear system where N = %d\", N);\n",
        "\n",
        "\tprintf(\"\\n\");\n",
        "\n",
        "  // Calculate Non-Zeros from original dense matrix\n",
        "\tint* nnz;\n",
        "\tcudaMallocManaged(&nnz, sizeof(int));\n",
        "\t*nnz = 0;\n",
        "\n",
        "\tfor (int i = 0; i < N * N; i++)\n",
        "\t{\n",
        "\t\tif (fabs(m->m[i]) > 0.0f)\n",
        "\t\t{\n",
        "\t\t\t(*nnz)++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"nnz: %d\\n\", *nnz);\n",
        "\n",
        "\tint totalANnz;\n",
        "\tint* nrows;\n",
        "\tint* ncolors;\n",
        "\tint* coloring;\n",
        "\tint* iterations;\n",
        "\tint* reordering;\n",
        "\tint* dANnzPerRow;\n",
        "\tint* dCsrRowPtrA;\n",
        "\tint* dCsrColIndA;\n",
        "\tint* max = new int;\n",
        "\tfloat* dM;\n",
        "\tfloat* dCsrValA;\n",
        "\tfloat* fractiontoColor;\n",
        "\tstd::vector<int> colors;\n",
        "\tgpuVec<int>* indices = new gpuVec<int>(N);\n",
        "\tgpuVec<float>* residual = new gpuVec<float>(N);\n",
        "\n",
        "\tcudaMalloc(&coloring, N * sizeof(float));\n",
        "\tcudaMalloc(&reordering, N * sizeof(float));\n",
        "\tcudaMalloc(&dM, N * N * sizeof(float));\n",
        "\tcudaMalloc((void**)&dANnzPerRow, sizeof(int) * N);\n",
        "\tcudaMallocManaged(&nrows, sizeof(int));\n",
        "\tcudaMallocManaged(&ncolors, sizeof(int));\n",
        "\tcudaMallocManaged(&iterations, sizeof(int));\n",
        "\tcudaMallocManaged(&fractiontoColor, sizeof(float));\n",
        "\n",
        "\tcusparseHandle_t handle = 0;\n",
        "\tcusparseCreate(&handle);\n",
        "\tcusparseColorInfo_t info;\n",
        "\tcusparseCreateColorInfo(&info);\n",
        "\n",
        "\tcusparseMatDescr_t Adescr = 0;\n",
        "\tcusparseCreateMatDescr(&Adescr);\n",
        "\tcusparseSetMatType(Adescr, CUSPARSE_MATRIX_TYPE_GENERAL);\n",
        "\tcusparseSetMatIndexBase(Adescr, CUSPARSE_INDEX_BASE_ZERO);\n",
        "\n",
        "\tcudaMemcpy(dM, m->m, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Total nnz, nnz per row\n",
        "\tcusparseSnnz(handle, CUSPARSE_DIRECTION_ROW, N, N, Adescr,\n",
        "\t\tdM, N, dANnzPerRow, &totalANnz);\n",
        "\n",
        "\tcudaMalloc((void**)&dCsrValA, sizeof(float) * totalANnz);\n",
        "\tcudaMalloc((void**)&dCsrRowPtrA, sizeof(int) * (N + 1));\n",
        "\tcudaMalloc((void**)&dCsrColIndA, sizeof(int) * totalANnz);\n",
        "\n",
        "\t*nrows = N;\n",
        "\t*ncolors = 0;\n",
        "\t*fractiontoColor = 0.15f;\n",
        "\n",
        "\t///////////////////////////////////////////////////// Start Processing\n",
        "\n",
        "\tauto started = std::chrono::high_resolution_clock::now();\n",
        "\tcolors = color(N, m, expected_solution, b, indices->v, max, dANnzPerRow, dCsrValA, dCsrRowPtrA, dCsrColIndA, nnz, handle, Adescr, dM, fractiontoColor, nrows, ncolors, coloring, reordering, info);\n",
        "\tauto done = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\tstd::cout << \"Graph Coloring CPU time: \" << std::chrono::duration_cast<std::chrono::milliseconds>(done - started).count() << \"ms\\n\";\n",
        "\n",
        "\tprintf(\"Max row length in CSR: %d\\n\", *max);\n",
        "\tprintf(\"number of colors: %zd\\n\", colors.size());\n",
        "\n",
        "  ///////////////////////////////////////////////////// End Processing\n",
        "\n",
        "\tdelete m;\n",
        "\tdelete x;\n",
        "\tdelete b;\n",
        "\tdelete residual;\n",
        "\tdelete expected_solution;\n",
        "\n",
        "\tcudaFree(dANnzPerRow);\n",
        "\tcudaFree(dCsrValA);\n",
        "\tcudaFree(dCsrRowPtrA);\n",
        "\tcudaFree(dCsrColIndA);\n",
        "\tcudaFree(dM);;\n",
        "\tcudaFree(coloring);\n",
        "\n",
        "\tcusparseDestroyMatDescr(Adescr);\n",
        "\tcusparseDestroy(handle);\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cCZywx452EG",
        "outputId": "8c2389ab-82a2-47f2-b9c0-77503c28e142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Kcsrcolortest.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<int> color(int, gpuMat*, gpuVec<float>*, gpuVec<float>*, int*, int*, int*, float*, int*, int*, int*, cusparseHandle_t, cusparseMatDescr_t, float*, float*, int*, int*, int*, int*, cusparseColorInfo_t)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kcsrcolortest.cu:107:96:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  107 |  cusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
            "      |                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kcsrcolortest.cu:107:96:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  107 |  cusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
            "      |                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "Gauss Seidel with Graph Coloring on the GPU using CuSparse\n",
            "percent of non-zeros of M: 0%\n",
            "solving linear system where N = 9669\n",
            "nnz: 38530\n",
            "colors used: 16\n",
            "fraction to color: 0.150000\n",
            "Graph Coloring CPU time: 430ms\n",
            "Max row length in CSR: 0\n",
            "number of colors: 16\n"
          ]
        }
      ],
      "source": [
        "!nvcc csrcolortest.cu -lcusparse -o sol1\n",
        "!./sol1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVY-XqkIQZNq"
      },
      "source": [
        "### GPU Graph Coloring using CSRColor (CuSparse)\n",
        "We use the coloring of CSRColor to reorder the initial dense matrix, and we apply the Gauss-Seidel kernel to it. Note that the value of N is twiddled up for the reduction kernel using: https://stackoverflow.com/questions/1322510/given-an-integer-how-do-i-find-the-next-largest-power-of-two-using-bit-twiddlin/1322548#1322548"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1b-AxeZQfNI",
        "outputId": "dbcca554-7d4d-4eb2-8183-d1d7b4f25110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting finalgaussseidel.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile finalgaussseidel.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "#include <set>\n",
        "#include <vector>\n",
        "#include <cusparse.h>\n",
        "#include <cusparse_v2.h>\n",
        "#include <algorithm>\n",
        "#include <fstream>\n",
        "\n",
        "const float EPS = 0.00001f;\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "\tif (err != cudaSuccess) {\n",
        "\t\tfprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "\t}\n",
        "\treturn err;\n",
        "}\n",
        "\n",
        "// vector of dimension Nx1\n",
        "template <class T>\n",
        "class gpuVec {\n",
        "public:\n",
        "\tT* v;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuVec(int size) {\n",
        "    N = size;\n",
        "\t\tcudaMallocManaged(&v, (T)(size * (int)sizeof(int)));\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tv[i] = 0;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuVec()\n",
        "\t{\n",
        "\t\tcudaFree(v);\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", v[i]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "};\n",
        "\n",
        "// matrix of dimension NxN.\n",
        "class gpuMat {\n",
        "public:\n",
        "\tfloat* m;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuMat(int n) {\n",
        "    N = n;\n",
        "\t\tcudaMallocManaged(&m, (float)(N * N * (int)sizeof(float)));\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tm[i] = 0.0f;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuMat()\n",
        "\t{\n",
        "\t\tcudaFree(m);\n",
        "\t}\n",
        "\n",
        "\t__host__ void printdiag() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\t{ printf(\"%f, \", m[i * N + i]); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", m[i]);\n",
        "\t\t\tif (i % N == 0 && i != 0) { printf(\"\\n\"); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "  // only used to get solution, b, from initial matrix, m.\n",
        "  __host__ gpuVec<float>* gpu_mult(const gpuVec<float>* v, gpuVec<float>* r) const {\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tr->v[row] += this->m[row * N + col] * v->v[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\treturn r;\n",
        "\t}\n",
        "};\n",
        "\n",
        "\n",
        "__global__ void gauss_seidel_partition(int N, float* x, const float* b, float* m, int* diags, int partition)\n",
        "{\n",
        "\textern __shared__ float cache[];\n",
        "\n",
        "\tint global_row = (blockIdx.x + partition);\n",
        "  float omega = 1.0f;\n",
        "\n",
        "\tint tid = threadIdx.x;\n",
        "\tfloat temp = 0.0f;\n",
        "\twhile (tid < N) {\n",
        "\t\t\ttemp += m[tid + (N * global_row)] * x[tid];\n",
        "\t\t\ttid += blockDim.x;\n",
        "\t}\n",
        "\n",
        "\tcache[threadIdx.x] = temp;\n",
        "\t__syncthreads();\n",
        "\n",
        "\tint i = blockDim.x / 2;\n",
        "\twhile (i != 0) {\n",
        "\t\tif (threadIdx.x < i)\n",
        "\t\t\tcache[threadIdx.x] += cache[threadIdx.x + i];\n",
        "\t\t__syncthreads();\n",
        "\t\ti /= 2;\n",
        "\t}\n",
        "\n",
        "\tif (threadIdx.x == 0)\n",
        "\t{\n",
        "\t\tint diag = diags[global_row];\n",
        "\t\tcache[0] -= m[diag + (N * global_row)] * x[diag];\n",
        "\t\tx[global_row] = (1.0f - omega)*x[global_row] + omega*(1.0f / m[diag + (N * global_row)]) * (b[global_row] - cache[0]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void gauss_seidel(int N, float* x, const float* b, float* m, int* colors, int ncolors, float* residual, int* iterations, int* indices) {\n",
        "\tint iter;\n",
        "\tfloat old_norm = 0.0f;\n",
        "\tint v = N;\n",
        "\tv--;\n",
        "\tv |= v >> 1;\n",
        "\tv |= v >> 2;\n",
        "\tv |= v >> 4;\n",
        "\tv |= v >> 8;\n",
        "\tv |= v >> 16;\n",
        "\tv++;\n",
        "\tint blockdim = std::min(v, 1024);\n",
        "\tint sharedsize = std::min(v, 1024)*sizeof(float);\n",
        "\n",
        "\tfor (iter = 0; iter < 100; ++iter) {\n",
        "\t\t*iterations = iter;\n",
        "\t\tint prev_color = 0;\n",
        "\t\tfor (int i = 1; i < ncolors; i += 1) {\n",
        "\t\t\tgauss_seidel_partition<<<colors[i] - prev_color, blockdim, sharedsize>>>(N, x, b, m, indices, colors[i - 1]);\n",
        "\t\t\tcudaDeviceSynchronize();\n",
        "\t\t\tprev_color = colors[i];\n",
        "\t\t}\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tresidual[row] += m[row * N + col] * x[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\tfloat norm = 0.0f;\n",
        "\t\tfloat c = 0.0f;\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tfloat a = residual[i] - b[i];\n",
        "\t\t\tresidual[i] = 0.0f;\n",
        "\t\t\tfloat y = a * a - c;\n",
        "\t\t\tfloat t = norm + y;\n",
        "\t\t\tc = (t - norm) - y;\n",
        "\t\t\tnorm = t;\n",
        "\t\t}\n",
        "\t\tnorm = sqrt(norm);\n",
        "\t\tif (fabs(norm - old_norm) < 0.0001f) {\n",
        "\t\t\treturn;\n",
        "\t\t}\n",
        "\t\told_norm = norm;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void jacobi_partition(int N, float* x, const float* b, float* m, int* diags)\n",
        "{\n",
        "\textern __shared__ float cache[];\n",
        "\n",
        "\tint global_row = blockIdx.x;\n",
        "  float omega = 1.0f;\n",
        "\n",
        "\tint tid = threadIdx.x;\n",
        "\tfloat temp = 0.0f;\n",
        "\twhile (tid < N) {\n",
        "\t\t\ttemp += m[tid + (N * global_row)] * x[tid];\n",
        "\t\t\ttid += blockDim.x;\n",
        "\t}\n",
        "\n",
        "\tcache[threadIdx.x] = temp;\n",
        "\t__syncthreads();\n",
        "\n",
        "\tint i = blockDim.x / 2;\n",
        "\twhile (i != 0) {\n",
        "\t\tif (threadIdx.x < i)\n",
        "\t\t\tcache[threadIdx.x] += cache[threadIdx.x + i];\n",
        "\t\t__syncthreads();\n",
        "\t\ti /= 2;\n",
        "\t}\n",
        "\n",
        "\tif (threadIdx.x == 0)\n",
        "\t{\n",
        "\t\tint diag = diags[global_row];\n",
        "\t\tcache[0] -= m[diag + (N * global_row)] * x[diag];\n",
        "\t\tx[global_row] = (1.0f - omega)*x[global_row] + omega*(1.0f / m[diag + (N * global_row)]) * (b[global_row] - cache[0]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void jacobi(int N, float* x, const float* b, float* m, int* colors, int ncolors, float* residual, int* iterations, int* indices) {\n",
        "\tint iter;\n",
        "\tfloat old_norm = 0.0f;\n",
        "\tint v = N;\n",
        "\tv--;\n",
        "\tv |= v >> 1;\n",
        "\tv |= v >> 2;\n",
        "\tv |= v >> 4;\n",
        "\tv |= v >> 8;\n",
        "\tv |= v >> 16;\n",
        "\tv++;\n",
        "\tint blockdim = std::min(v, 1024);\n",
        "\tint sharedsize = std::min(v, 1024)*sizeof(float);\n",
        "\n",
        "\tfor (iter = 0; iter < 100; ++iter) {\n",
        "\t\t*iterations = iter;\n",
        "\t\tjacobi_partition<<<N, blockdim, sharedsize>>>(N, x, b, m, indices);\n",
        "\t\tcudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tresidual[row] += m[row * N + col] * x[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\tfloat norm = 0.0f;\n",
        "\t\tfloat c = 0.0f;\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tfloat a = residual[i] - b[i];\n",
        "\t\t\tresidual[i] = 0.0f;\n",
        "\t\t\tfloat y = a * a - c;\n",
        "\t\t\tfloat t = norm + y;\n",
        "\t\t\tc = (t - norm) - y;\n",
        "\t\t\tnorm = t;\n",
        "\t\t}\n",
        "\t\tnorm = sqrt(norm);\n",
        "\t\tif (fabs(norm - old_norm) < 0.0001f) {\n",
        "\t\t\treturn;\n",
        "\t\t}\n",
        "\t\told_norm = norm;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "std::vector<int> color(int N, gpuMat* m, gpuVec<float>* x, gpuVec<float>* b, int* indices, int* max, int* dANnzPerRow,\n",
        "\tfloat* dCsrValA, int* dCsrRowPtrA, int* dCsrColIndA, int* totalANnz, cusparseHandle_t handle,\n",
        "\tcusparseMatDescr_t Adescr, float* dM, float* fractiontoColor, int* nrows, int* ncolors, int* coloring, int* reordering, cusparseColorInfo_t info)\n",
        "{\n",
        "\n",
        "  float* hCsrVal = (float*)malloc(*totalANnz * sizeof(float));\n",
        "\tint* hCsrRowPtr = (int*)malloc((N+1) * sizeof(int));\n",
        "  int* hCsrColPtr = (int*)malloc(*totalANnz * sizeof(int));\n",
        "\n",
        "\n",
        "\tcusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
        "\t\tdCsrValA, dCsrRowPtrA, dCsrColIndA);\n",
        "\n",
        "\tcusparseScsrcolor(handle, *nrows, *totalANnz, Adescr, dCsrValA, dCsrRowPtrA, dCsrColIndA, fractiontoColor, ncolors, coloring, reordering, info);\n",
        "\n",
        "\tprintf(\"colors used: %d\\nfraction to color: %f\\n\", *ncolors, *fractiontoColor);\n",
        "\n",
        "\n",
        "  cudaMemcpy(hCsrVal, dCsrValA, *totalANnz * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hCsrRowPtr, dCsrRowPtrA, (N+1) * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hCsrColPtr, dCsrColIndA, *totalANnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "  int old = 0;\n",
        "\t*max = 0;\n",
        "  for (int i = 0; i < (N+1); i++)\n",
        "  {\n",
        "\t\tif (hCsrRowPtr[i] - old > *max)\n",
        "\t\t{\n",
        "\t\t\t*max = hCsrRowPtr[i] - old;\n",
        "\t\t}\n",
        "  \told = hCsrRowPtr[i];\n",
        "  }\n",
        "\n",
        "\n",
        "\tint* h_colors = (int*)malloc(N * sizeof(int));\n",
        "\tint* h_colindices = (int*)malloc(N * sizeof(int));\n",
        "\tcudaMemcpy(h_colors, coloring, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\tcudaMemcpy(h_colindices, reordering, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\tstd::vector<std::pair<int, int>> new_order;\n",
        "\tfor (int i = 0; i < N; i++)\n",
        "\t{\n",
        "\t\tnew_order.push_back(std::make_pair(h_colors[i], h_colindices[i]));\n",
        "\t}\n",
        "\tstd::sort(std::begin(new_order), std::end(new_order));\n",
        "\n",
        "\n",
        "\tstd::vector<int> colors;\n",
        "\tint prev_color = -1;\n",
        "\tgpuMat* new_m = new gpuMat(N);\n",
        "\tgpuVec<float>* new_x = new gpuVec<float>(N); // reorder expected solution, not the x vector\n",
        "\tgpuVec<float>* new_b = new gpuVec<float>(N);\n",
        "\n",
        "\tfor (int i = 0; i < N; i++)\n",
        "\t{\n",
        "\t\tif (prev_color != new_order[i].first)\n",
        "\t\t{\n",
        "\t\t\tcolors.push_back(i);\n",
        "\t\t\tprev_color = new_order[i].first;\n",
        "\t\t}\n",
        "\t\tindices[i] = new_order[i].second;\n",
        "\n",
        "\t\tfloat* m_pt = m->m + (new_order[i].second * N);\n",
        "\t\tfloat* x_pt = x->v + (new_order[i].second);\n",
        "\t\tfloat* b_pt = b->v + (new_order[i].second);\n",
        "\n",
        "\t\tfloat* m_new_pt = new_m->m + (i * N);\n",
        "\t\tfloat* x_new_pt = new_x->v + (i);\n",
        "\t\tfloat* b_new_pt = new_b->v + (i);\n",
        "\n",
        "\t\tmemcpy(m_new_pt, m_pt, N * (sizeof(float)));\n",
        "\t\tmemcpy(x_new_pt, x_pt, (sizeof(float)));\n",
        "\t\tmemcpy(b_new_pt, b_pt, (sizeof(float)));\n",
        "\t}\n",
        "\n",
        "\tm->m = new_m->m;\n",
        "\tx->v = new_x->v;\n",
        "\tb->v = new_b->v;\n",
        "\n",
        "\treturn colors;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\tsrand(0);\n",
        "\n",
        "  std::ifstream file(\"content/flowmeter0/flowmeter0.mtx\");\n",
        "  int num_row, num_col, num_lines, N;\n",
        "\n",
        "  while (file.peek() == '%') file.ignore(2048, '\\n');\n",
        "\n",
        "  file >> num_row>> num_col >> num_lines;\n",
        "\n",
        "  N = num_row;\n",
        "\n",
        "  gpuMat* m = new gpuMat(num_row);\n",
        "  std::fill(m->m, m->m + num_row * num_col, 0.0f);\n",
        "\n",
        "  for (int l = 0; l < num_lines; l++)\n",
        "  {\n",
        "      float data;\n",
        "      int row, col;\n",
        "      file >> row >> col >> data;\n",
        "      m->m[(row -1) + (col -1) * num_row] = data;\n",
        "  }\n",
        "\n",
        "  file.close();\n",
        "\n",
        "\tint nonZeros = 0;\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tfor (int j = i; j < N; ++j) {\n",
        "\t\t\tif (fabs(m->m[i * N + j]) > EPS) {\n",
        "\t\t\t\tnonZeros++;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"Gauss Seidel with Graph Coloring on the GPU using CuSparse\\npercent of non-zeros of M: %d%%\\n\", int(100.0f * float(nonZeros) / float(N * N)));\n",
        "\n",
        "\tgpuVec<float>* expected_solution = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\texpected_solution->v[i] = 8.0f * float(rand() % 100) / 100.0f - 4.0f;\n",
        "\t}\n",
        "\n",
        "\tgpuVec<float>* b = new gpuVec<float>(N);\n",
        "\tb = m->gpu_mult(expected_solution, b);\n",
        "\n",
        "\tgpuVec<float>* x = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tx->v[i] = 0.0f;\n",
        "\t}\n",
        "\n",
        "\tprintf(\"solving linear system where N = %d\", N);\n",
        "\n",
        "\tprintf(\"\\n\");\n",
        "\n",
        "  // Calculate Non-Zeros from original dense matrix\n",
        "\tint* nnz;\n",
        "\tcudaMallocManaged(&nnz, sizeof(int));\n",
        "\t*nnz = 0;\n",
        "\n",
        "\tfor (int i = 0; i < N * N; i++)\n",
        "\t{\n",
        "\t\tif (fabs(m->m[i]) > 0.0f)\n",
        "\t\t{\n",
        "\t\t\t(*nnz)++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"nnz: %d\\n\", *nnz);\n",
        "\n",
        "\tint totalANnz;\n",
        "\tint* nrows;\n",
        "\tint* ncolors;\n",
        "\tint* coloring;\n",
        "\tint* iterations;\n",
        "\tint* reordering;\n",
        "\tint* dANnzPerRow;\n",
        "\tint* dCsrRowPtrA;\n",
        "\tint* dCsrColIndA;\n",
        "\tint* max = new int;\n",
        "\tfloat* dM;\n",
        "\tfloat* dCsrValA;\n",
        "\tfloat* fractiontoColor;\n",
        "\tstd::vector<int> colors;\n",
        "\tgpuVec<int>* indices = new gpuVec<int>(N);\n",
        "\tgpuVec<float>* residual = new gpuVec<float>(N);\n",
        "\n",
        "\tcudaMalloc(&coloring, N * sizeof(float));\n",
        "\tcudaMalloc(&reordering, N * sizeof(float));\n",
        "\tcudaMalloc(&dM, N * N * sizeof(float));\n",
        "\tcudaMalloc((void**)&dANnzPerRow, sizeof(int) * N);\n",
        "\tcudaMallocManaged(&nrows, sizeof(int));\n",
        "\tcudaMallocManaged(&ncolors, sizeof(int));\n",
        "\tcudaMallocManaged(&iterations, sizeof(int));\n",
        "\tcudaMallocManaged(&fractiontoColor, sizeof(float));\n",
        "\n",
        "\tfloat gpu_total = 0.0f;\n",
        "\tcudaEvent_t start, stop;\n",
        "\n",
        "\tcusparseHandle_t handle = 0;\n",
        "\tcusparseCreate(&handle);\n",
        "\tcusparseColorInfo_t info;\n",
        "\tcusparseCreateColorInfo(&info);\n",
        "\n",
        "\tcusparseMatDescr_t Adescr = 0;\n",
        "\tcusparseCreateMatDescr(&Adescr);\n",
        "\tcusparseSetMatType(Adescr, CUSPARSE_MATRIX_TYPE_GENERAL);\n",
        "\tcusparseSetMatIndexBase(Adescr, CUSPARSE_INDEX_BASE_ZERO);\n",
        "\n",
        "\tcudaMemcpy(dM, m->m, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Total nnz, nnz per row\n",
        "\tcusparseSnnz(handle, CUSPARSE_DIRECTION_ROW, N, N, Adescr,\n",
        "\t\tdM, N, dANnzPerRow, &totalANnz);\n",
        "\n",
        "\tcudaMalloc((void**)&dCsrValA, sizeof(float) * totalANnz);\n",
        "\tcudaMalloc((void**)&dCsrRowPtrA, sizeof(int) * (N + 1));\n",
        "\tcudaMalloc((void**)&dCsrColIndA, sizeof(int) * totalANnz);\n",
        "\n",
        "\t*nrows = N;\n",
        "\t*ncolors = 0;\n",
        "\t*fractiontoColor = 1.0f;\n",
        "\n",
        "\t///////////////////////////////////////////////////// Start Processing\n",
        "\n",
        "\tauto started = std::chrono::high_resolution_clock::now();\n",
        "\tcolors = color(N, m, expected_solution, b, indices->v, max, dANnzPerRow, dCsrValA, dCsrRowPtrA, dCsrColIndA, nnz, handle, Adescr, dM, fractiontoColor, nrows, ncolors, coloring, reordering, info);\n",
        "\tauto done = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\tstd::cout << \"Graph Coloring CPU time: \" << std::chrono::duration_cast<std::chrono::milliseconds>(done - started).count() << \"ms\\n\";\n",
        "\n",
        "\tprintf(\"Max row length in CSR: %d\\n\", *max);\n",
        "\n",
        "  // Copy coloring from CSRColor solution to GPU Gauss Seidel kernel\n",
        "\tgpuVec<int>* d_colors = new gpuVec<int>(colors.size());\n",
        "\tfor (int i = 0; i < colors.size(); i++)\n",
        "\t{\n",
        "\t\td_colors->v[i] = colors[i];\n",
        "\t}\n",
        "\n",
        "\tcudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "\tcudaEventRecord(start);\n",
        "\n",
        "\tgauss_seidel(N, x->v, b->v, m->m, d_colors->v, colors.size(), residual->v, iterations, indices->v);\n",
        "\t//jacobi(N, x->v, b->v, m->m, d_colors->v, colors.size(), residual->v, iterations, indices->v);\n",
        "\n",
        "\tcudaEventRecord(stop);\n",
        "\tcudaEventSynchronize(stop);\n",
        "\n",
        "\tcudaEventElapsedTime(&gpu_total, start, stop);\n",
        "\n",
        "\tprintf(\"Gauss Seidel GPU time: %fms\\n\", gpu_total);\n",
        "\n",
        "\tprintf(\"number of partitions: %zd\\n\", colors.size());\n",
        "\tprintf(\"number of iterations: %d\\n\", *iterations);\n",
        "\n",
        "  ///////////////////////////////////////////////////// End Processing\n",
        "\n",
        "\tdelete m;\n",
        "\tdelete x;\n",
        "\tdelete b;\n",
        "\tdelete residual;\n",
        "\tdelete expected_solution;\n",
        "\n",
        "\tcudaFree(dANnzPerRow);\n",
        "\tcudaFree(dCsrValA);\n",
        "\tcudaFree(dCsrRowPtrA);\n",
        "\tcudaFree(dCsrColIndA);\n",
        "\tcudaFree(dM);;\n",
        "\tcudaFree(coloring);\n",
        "\n",
        "\tcusparseDestroyMatDescr(Adescr);\n",
        "\tcusparseDestroy(handle);\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYu6avxSQiv9",
        "outputId": "873de0be-e380-43b7-ed35-3320c910bad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid gauss_seidel(int, float*, const float*, float*, int*, int, float*, int*, int*, int*, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:145:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  145 |     cusparseSdense2csr(handle, len, N, Adescr, dM, len, dANnzPerRow,\n",
            "      |                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:145:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  145 |     cusparseSdense2csr(handle, len, N, Adescr, dM, len, dANnzPerRow,\n",
            "      |                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<int> color(int, gpuMat*, gpuVec<float>*, gpuVec<float>*, int*, int*, int*, float*, int*, int*, int*, cusparseHandle_t, cusparseMatDescr_t, float*, float*, int*, int*, int*, int*, cusparseColorInfo_t)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:216:96:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  216 |  cusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
            "      |                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:216:96:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  216 |  cusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
            "      |                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "Gauss Seidel with Graph Coloring on the GPU using CuSparse\n",
            "percent of non-zeros of M: 0%\n",
            "solving linear system where N = 9669\n",
            "nnz: 38530\n",
            "colors used: 16\n",
            "fraction to color: 1.000000\n",
            "Graph Coloring CPU time: 517ms\n",
            "Max row length in CSR: 0\n",
            "Gauss Seidel GPU time: 3483.521973ms\n",
            "number of partitions: 16\n",
            "number of iterations: 9\n"
          ]
        }
      ],
      "source": [
        "!nvcc finalgaussseidel.cu -lcusparse -o sol2\n",
        "!./sol2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeL62c6oiJ_J"
      },
      "source": [
        "### Decompose Martix of n colors into n Sparse Matrices, apply SpMV to update *x*\n",
        "Create a CSR matrix for each reordered section of the colored matrix. Do SpMV for each color and the result is your solution in the range of the color. This is incomplete and not working correctly, likely due to some issue with my implementation of CuSparse SpMV. However, it is executing, so it is possible to time the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrFtPdTiiJXT",
        "outputId": "76e18548-7607-4c01-e26c-45d5ca8bbade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting finalgaussseidel.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile finalgaussseidel.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "#include <set>\n",
        "#include <vector>\n",
        "#include <cusparse.h>\n",
        "#include <cusparse_v2.h>\n",
        "#include <algorithm>\n",
        "#include <fstream>\n",
        "\n",
        "const float EPS = 0.00001f;\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "\tif (err != cudaSuccess) {\n",
        "\t\tfprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "\t}\n",
        "\treturn err;\n",
        "}\n",
        "\n",
        "// vector of dimension Nx1\n",
        "template <class T>\n",
        "class gpuVec {\n",
        "public:\n",
        "\tT* v;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuVec(int size) {\n",
        "    N = size;\n",
        "\t\tcudaMallocManaged(&v, (T)(size * (int)sizeof(int)));\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tv[i] = 0;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuVec()\n",
        "\t{\n",
        "\t\tcudaFree(v);\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", v[i]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "};\n",
        "\n",
        "// matrix of dimension NxN.\n",
        "class gpuMat {\n",
        "public:\n",
        "\tfloat* m;\n",
        "  int N;\n",
        "\n",
        "\t__host__ gpuMat(int n) {\n",
        "    N = n;\n",
        "\t\tcudaMallocManaged(&m, (float)(N * N * (int)sizeof(float)));\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tm[i] = 0.0f;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t__host__ ~gpuMat()\n",
        "\t{\n",
        "\t\tcudaFree(m);\n",
        "\t}\n",
        "\n",
        "\t__host__ void printdiag() {\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\t{ printf(\"%f, \", m[i * N + i]); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "\t__host__ void print() {\n",
        "\t\tfor (int i = 0; i < N * N; ++i) {\n",
        "\t\t\tprintf(\"%f, \", m[i]);\n",
        "\t\t\tif (i % N == 0 && i != 0) { printf(\"\\n\"); }\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "  // only used to get solution, b, from initial matrix, m.\n",
        "  __host__ gpuVec<float>* gpu_mult(const gpuVec<float>* v, gpuVec<float>* r) const {\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tr->v[row] += this->m[row * N + col] * v->v[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\treturn r;\n",
        "\t}\n",
        "};\n",
        "\n",
        "\n",
        "void gauss_seidel(int N, float* x, const float* b, float* m, int* colors, int ncolors,\n",
        "float* residual, int* iterations, int* indices, int* dANnzPerRow, int nnz)\n",
        "{\n",
        "\tint iter;\n",
        "\tfloat old_norm = 0.0f;\n",
        "\n",
        "\tfloat alpha = 1.0f;\n",
        "\tfloat beta = 0.0f;\n",
        "  float* dX;\n",
        "\tcudaMallocManaged(&dX, N*sizeof(float));\n",
        "\n",
        "\tfor (iter = 0; iter < 10; ++iter) {\n",
        "\t\t*iterations = iter;\n",
        "\t\tint global_row = 0;\n",
        "\t\tfor (int i = 1; i < ncolors; i += 1) {\n",
        "\n",
        "\t\t\t\tint len = indices[i]-indices[i-1];\n",
        "\t\t\t\tglobal_row += len;\n",
        "\t\t\t\t//printf(\"len: %d\\n\", len);\n",
        "\t\t\t\t//--------------------------------------------------------------------------\n",
        "\t\t\t\t// CUSPARSE APIs\n",
        "\t\t\t\tcusparseHandle_t handle = 0;\n",
        "\t\t\t\tcusparseCreate(&handle);\n",
        "\n",
        "\t\t\t\tcusparseMatDescr_t Adescr = 0;\n",
        "\t\t\t\tcusparseCreateMatDescr(&Adescr);\n",
        "\t\t\t\tcusparseSetMatType(Adescr, CUSPARSE_MATRIX_TYPE_GENERAL);\n",
        "\t\t\t\tcusparseSetMatIndexBase(Adescr, CUSPARSE_INDEX_BASE_ZERO);\n",
        "\n",
        "\t\t\t\tfloat* dM;\n",
        "\t\t\t\tfloat* val;\n",
        "\t\t\t\tfloat* dY;\n",
        "\t\t\t\tint* row;\n",
        "\t\t\t\tint* col;\n",
        "\t\t\t\tint totalANnz;\n",
        "\n",
        "\t\t\t\tcudaMallocManaged(&dM, len*N*sizeof(float));\n",
        "\t\t\t\tcudaMemcpy(dM, m+global_row*N, len * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\t\t\t\tcusparseSnnz(handle, CUSPARSE_DIRECTION_ROW, len, N, Adescr,\n",
        "\t\t\t\t\tdM, len, dANnzPerRow, &totalANnz);\n",
        "\n",
        "\t\t\t\tcudaMallocManaged(&val, totalANnz*sizeof(float));\n",
        "\t\t\t\tcudaMallocManaged(&col, totalANnz*sizeof(float));\n",
        "\t\t\t\tcudaMallocManaged(&row, (len+1)*sizeof(float));\n",
        "\t\t\t\tcudaMallocManaged(&dY, len*sizeof(float));\n",
        "\n",
        "\t\t\t\tcusparseSdense2csr(handle, len, N, Adescr, dM, len, dANnzPerRow,\n",
        "\t\t\t\t\tval, row, col);\n",
        "\n",
        "\t\t\t\tcusparseSpMatDescr_t matA;\n",
        "\t\t\t\tcusparseDnVecDescr_t vecX, vecY;\n",
        "\t\t\t\tvoid*                dBuffer    = NULL;\n",
        "\t\t\t\tsize_t               bufferSize = 0;\n",
        "\t\t\t\t// Create sparse matrix A in CSR format\n",
        "\t\t\t\tcusparseCreateCsr(&matA, len, N, totalANnz,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trow, col, val,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F);\n",
        "\t\t\t\t// Create dense vector X\n",
        "\t\t\t\tcusparseCreateDnVec(&vecX, N, dX, CUDA_R_32F);\n",
        "\t\t\t\t// Create dense vector Y\n",
        "\t\t\t\tcusparseCreateDnVec(&vecY, len, dY, CUDA_R_32F);\n",
        "\t\t\t\t// allocate an external buffer if needed\n",
        "\t\t\t\tcusparseSpMV_bufferSize(\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thandle, CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t&alpha, matA, vecX, &beta, vecY, CUDA_R_32F,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCUSPARSE_SPMV_ALG_DEFAULT, &bufferSize);\n",
        "\n",
        "\t\t\t\tcudaMalloc(&dBuffer, bufferSize);\n",
        "\t\t\t\t// execute SpMV\n",
        "\t\t\t\tcusparseSpMV(handle, CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
        "                                 &alpha, matA, vecX, &beta, vecY, CUDA_R_32F,\n",
        "                                 CUSPARSE_SPMV_ALG_DEFAULT, dBuffer);\n",
        "\n",
        "\t\t\t\tcudaMemcpy(&x[0]+colors[i], &dY[0]+colors[i], len*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\t\t\tcusparseDestroySpMat(matA);\n",
        "\t\t\tcusparseDestroyDnVec(vecX);\n",
        "\t\t\tcusparseDestroy(handle);\n",
        "\t\t}\n",
        "\n",
        "\t\tfor (int row = 0; row < N; ++row) {\n",
        "\t\t\tfor (int col = 0; col < N; ++col) {\n",
        "\t\t\t\tresidual[row] += m[row * N + col] * x[col];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\tfloat norm = 0.0f;\n",
        "\t\tfloat c = 0.0f;\n",
        "\t\tfor (int i = 0; i < N; ++i) {\n",
        "\t\t\tfloat a = residual[i] - b[i];\n",
        "\t\t\tresidual[i] = 0.0f;\n",
        "\t\t\tfloat y = a * a - c;\n",
        "\t\t\tfloat t = norm + y;\n",
        "\t\t\tc = (t - norm) - y;\n",
        "\t\t\tnorm = t;\n",
        "\t\t}\n",
        "\t\tnorm = sqrt(norm);\n",
        "\t\tif (fabs(norm - old_norm) < 0.0001f) {\n",
        "\t\t\t// destroy matrix/vector descriptors\n",
        "\t\t\t//return;\n",
        "\t\t}\n",
        "\t\told_norm = norm;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "std::vector<int> color(int N, gpuMat* m, gpuVec<float>* x, gpuVec<float>* b, int* indices, int* max, int* dANnzPerRow,\n",
        "\tfloat* dCsrValA, int* dCsrRowPtrA, int* dCsrColIndA, int* totalANnz, cusparseHandle_t handle,\n",
        "\tcusparseMatDescr_t Adescr, float* dM, float* fractiontoColor, int* nrows, int* ncolors, int* coloring, int* reordering, cusparseColorInfo_t info)\n",
        "{\n",
        "\n",
        "  float* hCsrVal = (float*)malloc(*totalANnz * sizeof(float));\n",
        "\tint* hCsrRowPtr = (int*)malloc((N+1) * sizeof(int));\n",
        "  int* hCsrColPtr = (int*)malloc(*totalANnz * sizeof(int));\n",
        "\n",
        "\n",
        "\tcusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
        "\t\tdCsrValA, dCsrRowPtrA, dCsrColIndA);\n",
        "\n",
        "\tcusparseScsrcolor(handle, *nrows, *totalANnz, Adescr, dCsrValA, dCsrRowPtrA, dCsrColIndA, fractiontoColor, ncolors, coloring, reordering, info);\n",
        "\n",
        "\tprintf(\"colors used: %d\\nfraction to color: %f\\n\", *ncolors, *fractiontoColor);\n",
        "\n",
        "\n",
        "  cudaMemcpy(hCsrVal, dCsrValA, *totalANnz * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hCsrRowPtr, dCsrRowPtrA, (N+1) * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hCsrColPtr, dCsrColIndA, *totalANnz * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "  int old = 0;\n",
        "\t*max = 0;\n",
        "  for (int i = 0; i < (N+1); i++)\n",
        "  {\n",
        "\t\tif (hCsrRowPtr[i] - old > *max)\n",
        "\t\t{\n",
        "\t\t\t*max = hCsrRowPtr[i] - old;\n",
        "\t\t}\n",
        "  \told = hCsrRowPtr[i];\n",
        "  }\n",
        "\n",
        "\n",
        "\tint* h_colors = (int*)malloc(N * sizeof(int));\n",
        "\tint* h_colindices = (int*)malloc(N * sizeof(int));\n",
        "\tcudaMemcpy(h_colors, coloring, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\tcudaMemcpy(h_colindices, reordering, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\tstd::vector<std::pair<int, int>> new_order;\n",
        "\tfor (int i = 0; i < N; i++)\n",
        "\t{\n",
        "\t\tnew_order.push_back(std::make_pair(h_colors[i], h_colindices[i]));\n",
        "\t}\n",
        "\tstd::sort(std::begin(new_order), std::end(new_order));\n",
        "\n",
        "\n",
        "\tstd::vector<int> colors;\n",
        "\tint prev_color = -1;\n",
        "\tgpuMat* new_m = new gpuMat(N);\n",
        "\tgpuVec<float>* new_x = new gpuVec<float>(N); // reorder expected solution, not the x vector\n",
        "\tgpuVec<float>* new_b = new gpuVec<float>(N);\n",
        "\n",
        "\tfor (int i = 0; i < N; i++)\n",
        "\t{\n",
        "\t\tif (prev_color != new_order[i].first)\n",
        "\t\t{\n",
        "\t\t\tcolors.push_back(i);\n",
        "\t\t\tprev_color = new_order[i].first;\n",
        "\t\t}\n",
        "\t\tindices[i] = new_order[i].second;\n",
        "\n",
        "\t\tfloat* m_pt = m->m + (new_order[i].second * N);\n",
        "\t\tfloat* x_pt = x->v + (new_order[i].second);\n",
        "\t\tfloat* b_pt = b->v + (new_order[i].second);\n",
        "\n",
        "\t\tfloat* m_new_pt = new_m->m + (i * N);\n",
        "\t\tfloat* x_new_pt = new_x->v + (i);\n",
        "\t\tfloat* b_new_pt = new_b->v + (i);\n",
        "\n",
        "\t\tmemcpy(m_new_pt, m_pt, N * (sizeof(float)));\n",
        "\t\tmemcpy(x_new_pt, x_pt, (sizeof(float)));\n",
        "\t\tmemcpy(b_new_pt, b_pt, (sizeof(float)));\n",
        "\t}\n",
        "\n",
        "\tm->m = new_m->m;\n",
        "\tx->v = new_x->v;\n",
        "\tb->v = new_b->v;\n",
        "\n",
        "\n",
        "\n",
        "\treturn colors;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\tsrand(0);\n",
        "\n",
        "  std::ifstream file(\"content/flowmeter0/flowmeter0.mtx\");\n",
        "  int num_row, num_col, num_lines, N;\n",
        "\n",
        "  while (file.peek() == '%') file.ignore(2048, '\\n');\n",
        "\n",
        "  file >> num_row>> num_col >> num_lines;\n",
        "\n",
        "  N = num_row;\n",
        "\n",
        "  gpuMat* m = new gpuMat(num_row);\n",
        "  std::fill(m->m, m->m + num_row * num_col, 0.0f);\n",
        "\n",
        "  for (int l = 0; l < num_lines; l++)\n",
        "  {\n",
        "      float data;\n",
        "      int row, col;\n",
        "      file >> row >> col >> data;\n",
        "      m->m[(row -1) + (col -1) * num_row] = data;\n",
        "  }\n",
        "\n",
        "  file.close();\n",
        "\n",
        "\tint nonZeros = 0;\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tfor (int j = i; j < N; ++j) {\n",
        "\t\t\tif (fabs(m->m[i * N + j]) > EPS) {\n",
        "\t\t\t\tnonZeros++;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"Gauss Seidel with Graph Coloring on the GPU using CuSparse\\npercent of non-zeros of M: %d%%\\n\", int(100.0f * float(nonZeros) / float(N * N)));\n",
        "\n",
        "\tgpuVec<float>* expected_solution = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\texpected_solution->v[i] = 8.0f * float(rand() % 100) / 100.0f - 4.0f;\n",
        "\t}\n",
        "\n",
        "\tgpuVec<float>* b = new gpuVec<float>(N);\n",
        "\tb = m->gpu_mult(expected_solution, b);\n",
        "\n",
        "\tgpuVec<float>* x = new gpuVec<float>(N);\n",
        "\tfor (int i = 0; i < N; ++i) {\n",
        "\t\tx->v[i] = 0.0f;\n",
        "\t}\n",
        "\n",
        "\tprintf(\"solving linear system where N = %d\", N);\n",
        "\n",
        "\tprintf(\"\\n\");\n",
        "\n",
        "  // Calculate Non-Zeros from original dense matrix\n",
        "\tint* nnz;\n",
        "\tcudaMallocManaged(&nnz, sizeof(int));\n",
        "\t*nnz = 0;\n",
        "\n",
        "\tfor (int i = 0; i < N * N; i++)\n",
        "\t{\n",
        "\t\tif (fabs(m->m[i]) > 0.0f)\n",
        "\t\t{\n",
        "\t\t\t(*nnz)++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"nnz: %d\\n\", *nnz);\n",
        "\n",
        "\tint totalANnz;\n",
        "\tint* nrows;\n",
        "\tint* ncolors;\n",
        "\tint* coloring;\n",
        "\tint* iterations;\n",
        "\tint* reordering;\n",
        "\tint* dANnzPerRow;\n",
        "\tint* dCsrRowPtrA;\n",
        "\tint* dCsrColIndA;\n",
        "\tint* max = new int;\n",
        "\tfloat* dM;\n",
        "\tfloat* dCsrValA;\n",
        "\tfloat* fractiontoColor;\n",
        "\tstd::vector<int> colors;\n",
        "\tgpuVec<int>* indices = new gpuVec<int>(N);\n",
        "\tgpuVec<float>* residual = new gpuVec<float>(N);\n",
        "\n",
        "\tcudaMalloc(&coloring, N * sizeof(float));\n",
        "\tcudaMalloc(&reordering, N * sizeof(float));\n",
        "\tcudaMalloc(&dM, N * N * sizeof(float));\n",
        "\tcudaMalloc((void**)&dANnzPerRow, sizeof(int) * N);\n",
        "\tcudaMallocManaged(&nrows, sizeof(int));\n",
        "\tcudaMallocManaged(&ncolors, sizeof(int));\n",
        "\tcudaMallocManaged(&iterations, sizeof(int));\n",
        "\tcudaMallocManaged(&fractiontoColor, sizeof(float));\n",
        "\n",
        "\tfloat gpu_total = 0.0f;\n",
        "\tcudaEvent_t start, stop;\n",
        "\n",
        "\tcusparseHandle_t handle = 0;\n",
        "\tcusparseCreate(&handle);\n",
        "\tcusparseColorInfo_t info;\n",
        "\tcusparseCreateColorInfo(&info);\n",
        "\n",
        "\tcusparseMatDescr_t Adescr = 0;\n",
        "\tcusparseCreateMatDescr(&Adescr);\n",
        "\tcusparseSetMatType(Adescr, CUSPARSE_MATRIX_TYPE_GENERAL);\n",
        "\tcusparseSetMatIndexBase(Adescr, CUSPARSE_INDEX_BASE_ZERO);\n",
        "\n",
        "\tcudaMemcpy(dM, m->m, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Total nnz, nnz per row\n",
        "\tcusparseSnnz(handle, CUSPARSE_DIRECTION_ROW, N, N, Adescr,\n",
        "\t\tdM, N, dANnzPerRow, &totalANnz);\n",
        "\n",
        "\tcudaMalloc((void**)&dCsrValA, sizeof(float) * totalANnz);\n",
        "\tcudaMalloc((void**)&dCsrRowPtrA, sizeof(int) * (N + 1));\n",
        "\tcudaMalloc((void**)&dCsrColIndA, sizeof(int) * totalANnz);\n",
        "\n",
        "\t*nrows = N;\n",
        "\t*ncolors = 0;\n",
        "\t*fractiontoColor = 1.0f;\n",
        "\n",
        "\t///////////////////////////////////////////////////// Start Processing\n",
        "\n",
        "\tauto started = std::chrono::high_resolution_clock::now();\n",
        "\tcolors = color(N, m, expected_solution, b, indices->v, max, dANnzPerRow, dCsrValA, dCsrRowPtrA, dCsrColIndA, nnz, handle, Adescr, dM, fractiontoColor, nrows, ncolors, coloring, reordering, info);\n",
        "\tauto done = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "\tstd::cout << \"Graph Coloring CPU time: \" << std::chrono::duration_cast<std::chrono::milliseconds>(done - started).count() << \"ms\\n\";\n",
        "\n",
        "\tprintf(\"Max row length in CSR: %d\\n\", *max);\n",
        "\n",
        "  // Copy coloring from CSRColor solution to GPU Gauss Seidel kernel\n",
        "\tgpuVec<int>* d_colors = new gpuVec<int>(colors.size());\n",
        "\tfor (int i = 0; i < colors.size(); i++)\n",
        "\t{\n",
        "\t\td_colors->v[i] = colors[i];\n",
        "\t}\n",
        "\n",
        "\n",
        "\tcudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "\tcudaEventRecord(start);\n",
        "\n",
        "\tgauss_seidel(N, x->v, b->v, m->m, d_colors->v, colors.size(), residual->v, iterations, indices->v, dANnzPerRow, totalANnz);\n",
        "\n",
        "\tcudaEventRecord(stop);\n",
        "\tcudaEventSynchronize(stop);\n",
        "\n",
        "\tcudaEventElapsedTime(&gpu_total, start, stop);\n",
        "\n",
        "\tprintf(\"Gauss Seidel GPU time: %fms\\n\", gpu_total);\n",
        "\n",
        "\tprintf(\"number of partitions: %zd\\n\", colors.size());\n",
        "\tprintf(\"number of iterations: %d\\n\", *iterations);\n",
        "\n",
        "  ///////////////////////////////////////////////////// End Processing\n",
        "\n",
        "\tdelete m;\n",
        "\tdelete x;\n",
        "\tdelete b;\n",
        "\tdelete residual;\n",
        "\tdelete expected_solution;\n",
        "\n",
        "\tcudaFree(dANnzPerRow);\n",
        "\tcudaFree(dCsrValA);\n",
        "\tcudaFree(dCsrRowPtrA);\n",
        "\tcudaFree(dCsrColIndA);\n",
        "\tcudaFree(dM);;\n",
        "\tcudaFree(coloring);\n",
        "\n",
        "\tcusparseDestroyMatDescr(Adescr);\n",
        "\tcusparseDestroy(handle);\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppbQIFgrjdRz",
        "outputId": "2fbd2d0d-7819-42f7-e839-16a476ffb160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid gauss_seidel(int, float*, const float*, float*, int*, int, float*, int*, int*, int*, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:145:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  145 |     cusparseSdense2csr(handle, len, N, Adescr, dM, len, dANnzPerRow,\n",
            "      |                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:145:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  145 |     cusparseSdense2csr(handle, len, N, Adescr, dM, len, dANnzPerRow,\n",
            "      |                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<int> color(int, gpuMat*, gpuVec<float>*, gpuVec<float>*, int*, int*, int*, float*, int*, int*, int*, cusparseHandle_t, cusparseMatDescr_t, float*, float*, int*, int*, int*, int*, cusparseColorInfo_t)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:216:96:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  216 |  cusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
            "      |                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kfinalgaussseidel.cu:216:96:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KcusparseStatus_t cusparseSdense2csr(cusparseHandle_t, int, int, cusparseMatDescr_t, const float*, int, const int*, float*, int*, int*)\u001b[m\u001b[K’ is deprecated: please use cusparseDenseToSparse instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "  216 |  cusparseSdense2csr(handle, N, N, Adescr, dM, N, dANnzPerRow,\n",
            "      |                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/cuda/bin/../targets/x86_64-linux/include/cusparse.h:4104:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " 4104 | \u001b[01;36m\u001b[KcusparseSdense2csr\u001b[m\u001b[K(cusparseHandle_t         handle,\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "Gauss Seidel with Graph Coloring on the GPU using CuSparse\n",
            "percent of non-zeros of M: 0%\n",
            "solving linear system where N = 9669\n",
            "nnz: 38530\n",
            "colors used: 16\n",
            "fraction to color: 1.000000\n",
            "Graph Coloring CPU time: 443ms\n",
            "Max row length in CSR: 0\n",
            "Gauss Seidel GPU time: 3466.364258ms\n",
            "number of partitions: 16\n",
            "number of iterations: 9\n"
          ]
        }
      ],
      "source": [
        "!nvcc finalgaussseidel.cu -lcusparse -o sol2\n",
        "!./sol2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbQysVy0li3"
      },
      "source": [
        "### Notes & Future Work\n",
        "\n",
        "- Under-relaxation was applied to select SuiteSparse matrices because the absence of an explicit 𝑏 vector prevented convergence; with extremely large coefficients in the matrix, iterative methods would otherwise diverge in the absence of a stabilizing factor\n",
        "- Contribute to an open source simulation repository that may use Preconditioned Conjugate Gradient or Jacobi or serial Gauss Seidel, and use a multicoloring approach. Note that grid based approaches do not benefit from multicoloring, as at most there would be 2 colors, known as red-black coloring. Thus, this is suited to some physics simulations. While there may not be an inner product at every update, there may be a constraint update such as in Position Based Dynamics. Thus, a constraint graph must be generated to parallelize it.\n",
        "- Use METIS library to partition into super nodes, color the super nodes and keep the processing of the super nodes, or color those individually. Note that this is only suitable for extremely large graphs with many SCC's. METIS is available to download with vcpkg. I have experimented with it but did not have time to get it working.\n",
        "- Genetic algorithms on the GPU to create the coloring may also be worth exploring, especially if when initially testing it out, it outperforms CSRColor by producing less colors and a valid configuration."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FYngqUpJA-Kd",
        "fucuNTsoANjF",
        "k_KcxG0oGHdY",
        "jVY-XqkIQZNq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "135b483c382348b8a87804e29f6d063b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14c4620a666d404ba571bad32c3bf069": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fae8cdb3a3b4821b1ee85304ac63d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be3e82fd2e54d559a951acaea32e2d7",
            "max": 487663,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_135b483c382348b8a87804e29f6d063b",
            "value": 487663
          }
        },
        "28bfe307f325422586e8c45a0c6d1654": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be3e82fd2e54d559a951acaea32e2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dac522d2199417aa5c51641cbf88ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6841fdb9a80f4059a28288519d418b5a",
              "IPY_MODEL_1fae8cdb3a3b4821b1ee85304ac63d06",
              "IPY_MODEL_64423b41e0c0452b90af24be3b3704d7"
            ],
            "layout": "IPY_MODEL_c9b438f4bc7941e98e6209ce49894dbf"
          }
        },
        "64423b41e0c0452b90af24be3b3704d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c4620a666d404ba571bad32c3bf069",
            "placeholder": "​",
            "style": "IPY_MODEL_c579f815ddd94c76ac2c518a8b2bf3cb",
            "value": " 491520/? [00:12&lt;00:00, 40512.74B/s]"
          }
        },
        "6841fdb9a80f4059a28288519d418b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28bfe307f325422586e8c45a0c6d1654",
            "placeholder": "​",
            "style": "IPY_MODEL_7ba385fee67f4c389a016731b50637ad",
            "value": "flowmeter0: "
          }
        },
        "7ba385fee67f4c389a016731b50637ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c579f815ddd94c76ac2c518a8b2bf3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9b438f4bc7941e98e6209ce49894dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}